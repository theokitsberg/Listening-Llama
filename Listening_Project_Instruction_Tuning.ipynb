{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers datasets peft accelerate trl bitsandbytes\n"
      ],
      "metadata": {
        "id": "KhwF4BMK6je5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y trl\n",
        "!pip install git+https://github.com/huggingface/trl.git\n"
      ],
      "metadata": {
        "id": "Bfsnuvu8VjB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()\n"
      ],
      "metadata": {
        "id": "Lc9NSRdy6ukL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"meta-llama/Llama-2-7b-hf\"\n"
      ],
      "metadata": {
        "id": "cQrwxSvS6zsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, use_auth_token=True)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    use_auth_token=True,\n",
        "    device_map=\"auto\",\n",
        "    load_in_4bit=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "3KfKIDZ87KaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "id": "cP4-1N0i7kA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_json(\"/content/CLEANED_FINAL_INSTRUCTION_DATA.jsonl\", lines=True)\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "STskJVEc7r9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "hf_dataset = Dataset.from_pandas(df[[\"prompt\", \"response\"]])\n",
        "hf_dataset\n"
      ],
      "metadata": {
        "id": "kVO9yIto70Tp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_and_tokenize(example):\n",
        "    formatted = f\"### Prompt:\\n{example['prompt']}\\n\\n### Response:\\n{example['response']}\"\n",
        "    return tokenizer(formatted, truncation=True, padding=\"max_length\", max_length=512)\n",
        "\n",
        "tokenized_dataset = hf_dataset.map(format_and_tokenize)\n",
        "tokenized_dataset\n"
      ],
      "metadata": {
        "id": "w5eFDchH73rr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.pad_token = tokenizer.eos_token\n"
      ],
      "metadata": {
        "id": "vLhugh2h8Jz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q_proj\", \"v_proj\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.CAUSAL_LM\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "model.print_trainable_parameters()\n"
      ],
      "metadata": {
        "id": "tculuRwz8jiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./nightline-llama7b-instruct\",\n",
        "    per_device_train_batch_size=2,\n",
        "    gradient_accumulation_steps=8,\n",
        "    learning_rate=2e-5,\n",
        "    num_train_epochs=3,\n",
        "    logging_steps=20,\n",
        "    save_strategy=\"epoch\",\n",
        "    report_to=\"none\",\n",
        "    fp16=True,\n",
        "    push_to_hub=False\n",
        ")\n"
      ],
      "metadata": {
        "id": "BududvTQ808Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False\n",
        ")\n"
      ],
      "metadata": {
        "id": "owl-Yvps81_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator\n",
        ")\n"
      ],
      "metadata": {
        "id": "e3_gJzZ684Pz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "3KryB6ng8_Wl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"nightline-lora-adapter\")\n",
        "tokenizer.save_pretrained(\"nightline-lora-adapter\")\n"
      ],
      "metadata": {
        "id": "K2y9VxraQv5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r nightline-lora-adapter.zip nightline-lora-adapter\n"
      ],
      "metadata": {
        "id": "BxmPOeFZQ41_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}