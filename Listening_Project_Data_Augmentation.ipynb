{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q anthropic\n",
        "\n",
        "import anthropic\n",
        "import json\n",
        "import random\n",
        "import time\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "\n",
        "# ←——– your API key\n",
        "client = anthropic.Anthropic(\n",
        "    api_key=\"sk-ant-api03-\"\n",
        ")\n",
        "\n",
        "# ─── Load base dataset ───────────────────────────────────────────────────────\n",
        "with open(\"/content/nightline_data.jsonl\", \"r\") as f:\n",
        "    base_data = [json.loads(line) for line in f]\n",
        "\n",
        "output_path = \"/content/nightline_final_15x_dataset.jsonl\"\n",
        "\n",
        "# ─── 1) One-time copy of the latest interim backup ─────────────────────────\n",
        "interim_files = sorted(\n",
        "    glob.glob(\"/content/interim_backup_*.jsonl\"),\n",
        "    key=lambda p: int(os.path.basename(p).split(\"_\")[-1].split(\".\")[0])\n",
        ")\n",
        "if interim_files:\n",
        "    latest = interim_files[-1]\n",
        "    if not os.path.exists(output_path) or os.path.getsize(output_path) == 0:\n",
        "        shutil.copy(latest, output_path)\n",
        "        print(f\"✅ Initialized {output_path} from {latest}\")\n",
        "    else:\n",
        "        print(f\"✅ {output_path} already exists; skipping copy\")\n",
        "else:\n",
        "    print(\"⚠️ No interim_backup_*.jsonl files found; starting fresh\")\n",
        "\n",
        "# ─── 2) Compute how many entries we already have ────────────────────────────\n",
        "# 2) Compute how many base prompts are already done\n",
        "# 2) Compute how many *original* base prompts are already done\n",
        "start_i = 480  # You've already processed 480 prompts with 15 rewrites each\n",
        "start_j = 0\n",
        "print(f\"🔁 Resuming from prompt #{start_i}, rewrite #{start_j} of 5\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ─── 3) Open output for crash-safe appending ───────────────────────────────\n",
        "out_f = open(output_path, \"a\")\n",
        "\n",
        "# ─── 4) Prompt & response specs ────────────────────────────────────────────\n",
        "themes = \"\"\"friend issues, loneliness, body image, panic attacks, shame/guilt,\n",
        "family issues, eating disorder, trust issues, emotional numbness, overwhelm,\n",
        "anger issues, school stress, social anxiety, relationship problems,\n",
        "gender/sexuality, low self-esteem, grief, disconnection, perfectionism,\n",
        "jealousy, career stress, fear of judgment, anxiety, bullying, self-harm,\n",
        "suicidal intent, dissociation\"\"\"\n",
        "\n",
        "rewrite_instruction = f\"\"\"Rewrite the emotional disclosure below **5 times**.\n",
        "\n",
        "Each version should preserve the original emotional meaning, but vary in:\n",
        "- Perspective (e.g., “I”, “sometimes it feels like”, “lately…”)\n",
        "- Depth (short vs expanded)\n",
        "- Voice (plain vs metaphorical, vague vs raw)\n",
        "\n",
        "You may draw on these emotional themes for variety — but do not invent new feelings\n",
        "not present in the original and also try to avoid oversentementalising or coming off too poetic:\n",
        "{themes}\n",
        "\n",
        "⚠️ Return the rewrites only — no commentary, no headers, no numbering. One per line.\n",
        "\"\"\"\n",
        "\n",
        "# A small set of example closers for inspiration only\n",
        "nightline_closers = [\n",
        "    \"Does that resonate with you?\",\n",
        "    \"How does that sit with you?\",\n",
        "    \"Is there anything else on your mind?\",\n",
        "    \"How are you feeling at this moment?\"\n",
        "]\n",
        "\n",
        "def get_response_instruction():\n",
        "    examples = \"  \".join(f\"“{c}”\" for c in nightline_closers)\n",
        "    return f\"\"\"Generate three distinct responses to the emotional disclosure below:\n",
        "\n",
        "1. A directive response: give clear, actionable advice or a suggestion. Be\n",
        "   confident but not harsh or judgmental. Encourage forward motion, not emotional\n",
        "   shutdown.\n",
        "\n",
        "2. A neutral response: briefly acknowledge what was said. Keep it emotionally\n",
        "   polite but detached — not warm, not cold. Don’t offer advice, praise, or\n",
        "   reflection. Just acknowledge.\n",
        "\n",
        "3. A Nightline-aligned response: Generate responses that replicate the tone and conversational style of a trained Nightline volunteer. Keep responses emotionally grounded, calm, and empathetic. Avoid heightened emotional language or cheeriness. Don’t say things like “That sounds terrible, I’m so sorry that happened!” Instead, say “It sounds like you’ve been carrying a lot lately.” Show empathy without dramatizing.\n",
        "\n",
        "Reflect and mirror the user’s words through paraphrasing. Don’t repeat their exact phrasing. Show that you're listening by summarizing or exploring what they’ve said. If someone says they’re struggling after returning to university, respond with something like “You mentioned that you’re feeling overwhelmed since coming back to uni — that sounds really tough.”\n",
        "\n",
        "Use open-ended, curious questions that help the user explore their thoughts and feelings. Don’t interrogate or pressure. Never give advice. Don’t say “Have you tried talking to your tutor about it?” Instead, say “What do you feel might help, even a little, right now?” or “Would you like to talk more about what’s been making you feel that way?”\n",
        "\n",
        "Avoid being directive. Never tell users what to do. Don’t offer suggestions, solutions, or hypothetical advice. Never say “You should…” or “If I were you…” Instead, ask “What’s your sense of what might be helpful right now?” or “Have you had any thoughts on what kind of support you’d want?”\n",
        "\n",
        "Remain completely non-judgemental. Don’t praise or criticize actions or feelings. Avoid saying “That’s good you’re trying to quit” or “You probably shouldn’t do that.” These are judgments, even if well-meant. Instead, say “It makes sense that you’d feel conflicted — a lot’s been going on.”\n",
        "\n",
        "Keep yourself out of the conversation. Don’t refer to your own experiences, opinions, or perspectives. Never say “I’ve been there” or “I know how that feels.” Instead, say “Sounds like this has been on your mind a lot. What’s been the hardest part of it for you?”\n",
        "\n",
        "Maintain a gentle, unhurried pace. Embrace pauses. Don’t rush or fill silences. Say things like “Take your time. I’m here to listen.”\n",
        "\n",
        "Avoid sounding robotic or scripted. If a phrase starts to feel stale, vary it or rephrase. Don’t overuse stock responses like “That must be hard.” Instead, personalize it: “That sounds really difficult,” or “I can see why that would feel heavy.” Use clarifying questions to deepen the conversation, such as “It sounds as though you felt overwhelmed when that happened — is that right?”\n",
        "\n",
        "Always ground responses in the principles of non-directivity, non-judgement, anonymity, and confidentiality. Do not fix, advise, diagnose, or lead. Just hold space. Listen. Reflect. Support.\n",
        "\n",
        "For inspiration, here are a few example closers:\n",
        "{examples}\n",
        "\n",
        "Feel free to create your own natural-sounding closer at the end of your Nightline-aligned response. Do **not** prefix it with bullets, dashes, or slashes.\n",
        "\n",
        "⚠️ Return only the three responses, one per line, in plain text.\"\"\"\n",
        "\n",
        "# ─── 5) Generation loop with resume & interim backups ───────────────────────\n",
        "for i, entry in enumerate(base_data):\n",
        "    if i < start_i:\n",
        "        continue  # skip fully done prompts\n",
        "\n",
        "    base_prompt = entry[\"prompt\"]\n",
        "    traits      = entry[\"responses\"]\n",
        "\n",
        "    print(f\"\\n🔄 [{i+1}/{len(base_data)}] Rewriting prompt:\\n→ {base_prompt[:90]}...\\n\")\n",
        "\n",
        "    # 5.1) Get 15 rewrites\n",
        "    prompt_resp = client.messages.create(\n",
        "        model=\"claude-3-5-haiku-20241022\",\n",
        "        max_tokens=1500,\n",
        "        temperature=0.7,\n",
        "        messages=[{\n",
        "            \"role\": \"user\",\n",
        "            \"content\": rewrite_instruction + f'\\n\\n\"{base_prompt}\"'\n",
        "        }]\n",
        "    )\n",
        "    rewritten_prompts = [\n",
        "        p.strip() for p in prompt_resp.content[0].text.strip().split(\"\\n\")\n",
        "        if p.strip()\n",
        "    ]\n",
        "\n",
        "    for j, new_prompt in enumerate(rewritten_prompts):\n",
        "        if i == start_i and j < start_j:\n",
        "            continue  # skip already-done rewrites\n",
        "\n",
        "        print(f\"📝 [{j+1}/5] {new_prompt[:90]}...\")\n",
        "\n",
        "        # 5.2) Get 3 responses\n",
        "        response_block = client.messages.create(\n",
        "            model=\"claude-3-5-haiku-20241022\",\n",
        "            max_tokens=1000,\n",
        "            temperature=0.7,\n",
        "            messages=[{\n",
        "                \"role\": \"user\",\n",
        "                \"content\": get_response_instruction() + f'\\n\\nPrompt: \"{new_prompt}\"'\n",
        "            }]\n",
        "        )\n",
        "        responses = [\n",
        "            r.strip() for r in response_block.content[0].text.strip().split(\"\\n\")\n",
        "            if r.strip()\n",
        "        ]\n",
        "        responses = responses[-3:] if len(responses) >= 3 else responses\n",
        "\n",
        "        if len(responses) == 3:\n",
        "            record = {\n",
        "                \"prompt\": new_prompt,\n",
        "                \"responses\": {\n",
        "                    \"directive\": {\n",
        "                        \"text\":   responses[0],\n",
        "                        \"traits\": traits[\"directive\"][\"traits\"]\n",
        "                    },\n",
        "                    \"neutral\": {\n",
        "                        \"text\":   responses[1],\n",
        "                        \"traits\": traits[\"neutral\"][\"traits\"]\n",
        "                    },\n",
        "                    \"nightline_aligned\": {\n",
        "                        \"text\":   responses[2],\n",
        "                        \"traits\": traits[\"nightline_aligned\"][\"traits\"]\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "            json.dump(record, out_f)\n",
        "            out_f.write(\"\\n\")\n",
        "            out_f.flush()\n",
        "        else:\n",
        "            print(f\"⚠️ Expected 3 responses but got {len(responses)}; raw:\\n\"\n",
        "                  f\"{response_block.content[0].text}\")\n",
        "\n",
        "        time.sleep(1.1)\n",
        "\n",
        "    # 5.3) Every 10 base-prompts, save an interim backup\n",
        "    if (i + 1) % 10 == 0:\n",
        "        out_f.flush()\n",
        "        backup_name = f\"/content/interim_backup_{i+1}.jsonl\"\n",
        "        shutil.copy(output_path, backup_name)\n",
        "        print(f\"💾 Interim backup saved: {backup_name}\")\n",
        "\n",
        "    # only skip those j < start_j once\n",
        "    start_j = 0\n",
        "\n",
        "out_f.close()\n",
        "print(\"✅ Generation complete – all new rewrites & responses appended.\")\n"
      ],
      "metadata": {
        "id": "k9tUtm9mMZIl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}