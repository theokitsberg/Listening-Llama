{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers accelerate bitsandbytes peft trl datasets huggingface_hub xformers\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "bG92TewIZHdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean environment and pull the exact correct version of `trl`\n",
        "!pip uninstall -y trl\n",
        "!pip install git+https://github.com/huggingface/trl.git@main\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "2Wl5oJkTRzix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import DPOTrainer, DPOConfig\n"
      ],
      "metadata": {
        "id": "okXOTY-oU8r6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import DPOTrainer\n",
        "help(DPOTrainer)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "jl6s0YLBUQaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "# Paste your Hugging Face token here\n",
        "login(\"my llama code\")\n"
      ],
      "metadata": {
        "id": "pJvmcey8LQgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload the LoRA adapter (nightline-lora-adapter.zip)\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Upload the DPO dataset (cleaned_final_dpo_data.jsonl)\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "id": "NUjGBtw0MUKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip nightline-lora-adapter.zip -d nightline-lora-adapter\n"
      ],
      "metadata": {
        "id": "wGzPQX40OVsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls nightline-lora-adapter/nightline-lora-adapter\n"
      ],
      "metadata": {
        "id": "BtAO98CIQkDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from peft import PeftModel\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    \"meta-llama/Llama-2-7b-hf\",\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "\n",
        "# Load base model\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"meta-llama/Llama-2-7b-hf\",\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=\"auto\",\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "\n",
        "# Load LoRA adapter from nested folder\n",
        "model = PeftModel.from_pretrained(\n",
        "    model,\n",
        "    \"./nightline-lora-adapter/nightline-lora-adapter\",\n",
        ")\n"
      ],
      "metadata": {
        "id": "AiBWudg3Qosk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.pad_token = tokenizer.eos_token\n"
      ],
      "metadata": {
        "id": "eFRXYt9lWJPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load your DPO dataset\n",
        "dataset = load_dataset(\"json\", data_files=\"CLEANED_FINAL_DPO_DATA.jsonl\", split=\"train\")\n",
        "\n",
        "# Show the first sample to confirm structure\n",
        "dataset[0]\n"
      ],
      "metadata": {
        "id": "ZStPFeQfRM_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import DPOTrainer, DPOConfig\n",
        "from peft import PeftModel\n",
        "\n",
        "# üîß Set pad token (needed for DPOTrainer)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# üß† Ensure model is in training mode\n",
        "model.train()\n",
        "\n",
        "# üîì Unfreeze LoRA adapter weights, freeze base model\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "for name, param in model.named_parameters():\n",
        "    if \"lora\" in name:\n",
        "        param.requires_grad = True\n",
        "\n",
        "# üõ†Ô∏è Optional: confirm what's trainable\n",
        "if isinstance(model, PeftModel):\n",
        "    model.print_trainable_parameters()\n",
        "\n",
        "# ‚öôÔ∏è Define training config\n",
        "training_args = DPOConfig(\n",
        "    beta=0.1,\n",
        "    output_dir=\"./dpo-tuned-llama\",\n",
        "    per_device_train_batch_size=2,\n",
        "    gradient_accumulation_steps=8,\n",
        "    learning_rate=5e-5,\n",
        "    num_train_epochs=3,\n",
        "    logging_steps=10,\n",
        "    save_steps=100,\n",
        "    save_strategy=\"steps\",\n",
        "    bf16=True,  # or fp16=True\n",
        "    report_to=\"none\",\n",
        "    padding_value=tokenizer.pad_token_id,\n",
        ")\n",
        "\n",
        "# üöÄ Initialize DPO trainer\n",
        "trainer = DPOTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset,\n",
        "    processing_class=tokenizer,\n",
        ")\n",
        "\n",
        "# üèÅ Begin training\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "px1R3W1RROhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save LoRA adapter to directory\n",
        "adapter_save_path = \"./dpo_lora_adapter\"\n",
        "model.save_pretrained(adapter_save_path)\n",
        "tokenizer.save_pretrained(adapter_save_path)\n",
        "print(f\"LoRA adapter saved to: {adapter_save_path}\")\n"
      ],
      "metadata": {
        "id": "tc_Z-Net1bwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import PeftModel\n",
        "\n",
        "# Merge LoRA into the base model\n",
        "merged_model = model.merge_and_unload()\n",
        "\n",
        "# Save the fully merged model\n",
        "merged_model_path = \"./dpo_merged_model\"\n",
        "merged_model.save_pretrained(merged_model_path)\n",
        "tokenizer.save_pretrained(merged_model_path)\n",
        "print(f\"Merged model saved to: {merged_model_path}\")\n"
      ],
      "metadata": {
        "id": "FnQcLPsz1gqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('dpo_lora_adapter.zip')\n"
      ],
      "metadata": {
        "id": "hlWINX4f1ygp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}